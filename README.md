# PLI - Progressive Layer Increase

In this work, we introduce PLI (Progressive Layer Increase): a training method for transformer-based models like BERT, where layers are progressively added and trained in a stepwise manner. Unlike more traditional approaches that train all layers simultaneously, our method begins with only a few layers, and at different times during the training process, new layers are added incrementally. This gradual increase is possible due to the transformers' layer based architecture, where aside from the input and output layers, all the hidden layers are architecturally identical. Our experimental results demonstrate that this approach accelerates the early stages of the training process while maintaining competitive final performance.
